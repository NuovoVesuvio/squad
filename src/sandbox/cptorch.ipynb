{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, sys\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, value=0.001):\n",
    "        return Variable(torch.from_numpy(np.random.uniform(low=-value, high=value, size=(1,self.hidden_size))).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNorm(i2o):\n",
    "    return np.linalg.norm(i2o, ord='fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- import embeddings\n",
    "with open('../../data/lemmas_embeddings.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vocab', 'embeddings'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17663"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = data['embeddings'].astype(np.float32)\n",
    "vocab = data['vocab']\n",
    "reverse = {v:k for k,v in vocab.items()}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- load lemma text\n",
    "with open('../../data/lemmas.pickle', 'rb') as g:\n",
    "    lemma = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "hidden_dim = 100\n",
    "rnn = RNN(embedding_size, hidden_dim, len(vocab)).cuda()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.0001, momentum=0.02, weight_decay=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(lemma):\n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0.0\n",
    "    for i in range(len(sentence) - 1):\n",
    "        try: # -- get rid of digits in vocab\n",
    "            current_word = sentence[i]\n",
    "            current_index = vocab[current_word]\n",
    "            current_embedding = torch.from_numpy(embeddings[current_index]).unsqueeze(0)\n",
    "            vembedding = Variable(current_embedding).cuda()\n",
    "            next_word = torch.from_numpy(np.array([vocab[sentence[i+1]]]))\n",
    "            output, hidden = rnn(vembedding, hidden.cuda())\n",
    "            loss += criterion(output, Variable(next_word).cuda())\n",
    "\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    _hidden = rnn.initHidden()\n",
    "    if i == 0:\n",
    "        word = 'b'\n",
    "        next_word = torch.from_numpy(embeddings[vocab[word]]).unsqueeze(0)\n",
    "    print(word)\n",
    "    _output, _hidden = rnn(Variable(next_word).cuda(), _hidden.cuda())\n",
    "    probs = np.exp(_output.data.cpu().numpy().ravel())\n",
    "    amax = np.argmax(probs)\n",
    "    word = reverse[amax]\n",
    "    next_word = torch.from_numpy(embeddings[vocab[word]]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute norm of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "hidden_dim = 100\n",
    "vocab_size = 100\n",
    "rnn = RNN(embedding_size, hidden_dim, vocab_size).cuda()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.0001, momentum=0.02, weight_decay=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parm in rnn.parameters():\n",
    "    parm.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.00102 6.94652 28.4438\n",
      "1 27.665 111.153 48.0943\n",
      "2 8.68394 27.0407 23.2355\n",
      "3 10.0539 18.525 43.0136\n",
      "4 5.4819 16.115 21.4013\n",
      "5 7.08332 15.76 34.4673\n",
      "6 15.5867 38.8045 22.886\n",
      "7 17.3505 53.2685 37.4421\n",
      "8 10.4344 22.9897 32.6837\n",
      "9 4.19784 9.43011 17.7511\n",
      "10 4.09357 4.68125 19.1784\n",
      "11 8.97172 15.6166 26.7831\n",
      "12 6.66302 8.04506 22.9977\n",
      "13 29.7504 81.2312 33.1098\n",
      "14 7.03675 16.544 31.3246\n",
      "15 13.7566 48.2204 38.1774\n",
      "16 2.60717 4.0136 14.1946\n",
      "17 4.66888 5.19463 15.014\n",
      "18 10.4952 24.9476 29.7376\n",
      "19 4.39865 9.23239 20.6538\n",
      "20 7.30202 10.6385 30.5975\n",
      "21 14.2109 40.6298 18.3761\n",
      "22 27.3421 93.8539 37.5096\n",
      "23 15.1732 41.9079 31.9011\n",
      "24 14.2663 28.1796 24.7966\n",
      "25 11.8236 31.0986 24.2477\n",
      "26 6.39691 10.7796 21.2292\n",
      "27 8.34457 23.9766 22.1174\n",
      "28 7.4809 15.1798 40.5001\n",
      "29 18.5032 51.8982 43.5337\n",
      "30 18.4574 48.4326 37.3832\n",
      "31 8.83204 26.1046 22.6469\n",
      "32 9.43912 28.6126 28.8431\n",
      "33 13.6185 38.2131 41.5015\n",
      "34 7.22373 12.5876 24.0256\n",
      "35 12.3383 31.8123 30.5087\n",
      "36 5.98024 8.58123 22.2111\n",
      "37 4.60865 6.46872 19.894\n",
      "38 6.62877 16.4983 23.5768\n",
      "39 8.00488 14.0454 21.8673\n",
      "40 11.1607 26.7717 19.9305\n",
      "41 10.0881 13.7573 15.6713\n",
      "42 15.3788 46.5797 31.1389\n",
      "43 5.68025 7.97517 28.8531\n",
      "44 4.26307 10.551 13.6272\n",
      "45 9.28964 11.5261 26.9977\n",
      "46 10.4109 21.1137 26.9268\n",
      "47 5.48513 8.85508 25.2935\n",
      "48 10.0025 16.0791 30.215\n",
      "49 6.75662 14.7907 30.2711\n",
      "50 8.0157 17.4745 22.7109\n",
      "51 9.51693 14.6145 27.932\n",
      "52 10.505 20.4027 21.3206\n",
      "53 9.08806 19.3823 35.6996\n",
      "54 7.07064 9.26268 29.6418\n",
      "55 4.42864 5.54656 25.5564\n",
      "56 12.2418 16.2159 25.9007\n",
      "57 9.35888 28.7311 27.2802\n",
      "58 10.203 22.7955 34.4269\n",
      "59 6.04712 19.1671 23.5174\n",
      "60 18.8637 45.3954 24.2837\n",
      "61 5.22579 8.43452 23.3753\n",
      "62 13.0499 33.1845 38.9042\n",
      "63 16.7422 38.0013 44.7352\n",
      "64 5.74259 7.01462 32.7181\n",
      "65 19.0667 25.2213 37.7774\n",
      "66 6.04942 8.87697 25.6156\n",
      "67 7.15363 10.2436 29.715\n",
      "68 17.6475 38.9321 30.3596\n",
      "69 11.9436 22.1047 31.8751\n",
      "70 8.27993 10.763 34.5236\n",
      "71 8.86248 21.4814 17.1448\n",
      "72 7.2529 12.3696 22.7151\n",
      "73 14.9612 37.2643 33.1025\n",
      "74 4.59137 6.02037 29.5158\n",
      "75 10.2621 35.403 30.5368\n",
      "76 3.94416 6.27999 18.492\n",
      "77 15.3347 23.4695 24.5345\n",
      "78 12.9147 24.8766 27.8832\n",
      "79 5.79708 13.5058 24.8794\n",
      "80 10.6736 26.6519 22.7865\n",
      "81 10.9683 13.3271 25.1596\n",
      "82 9.55299 14.7612 30.9095\n",
      "83 5.67956 8.21926 22.2185\n",
      "84 18.8304 68.7242 41.0854\n",
      "85 7.64632 16.4936 38.2375\n",
      "86 7.19236 10.2191 28.5903\n",
      "87 6.67467 14.0952 29.0733\n",
      "88 12.0385 11.985 24.9336\n",
      "89 12.4509 39.8107 30.9468\n",
      "90 5.13422 6.82965 24.6203\n",
      "91 6.50009 9.64913 15.0605\n",
      "92 5.78737 7.26212 29.3473\n",
      "93 11.5025 12.2872 11.2381\n",
      "94 10.1139 14.5788 27.3506\n",
      "95 8.53338 12.3132 21.6171\n",
      "96 8.4673 14.0185 22.9151\n",
      "97 29.9468 73.7454 28.7845\n",
      "98 6.30588 10.7728 24.4373\n",
      "99 9.08083 15.0734 25.7049\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0.0\n",
    "    for i in range(10 - 1):\n",
    "        try: # -- get rid of digits in vocab\n",
    "            current_embedding = torch.from_numpy(embeddings[np.random.randint(10)]).unsqueeze(0)\n",
    "            vembedding = Variable(current_embedding, requires_grad=True).cuda()\n",
    "            next_word = torch.from_numpy(np.array([np.random.randint(10)]))\n",
    "            output, hidden = rnn(vembedding, hidden.cuda())\n",
    "            loss += criterion(output, Variable(next_word).cuda())\n",
    "            torch.nn.utils.clip_grad_norm(rnn.parameters(), 0.25)\n",
    "\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    i2o = rnn.i2o.weight.grad.data.cpu().numpy()\n",
    "    i2h = rnn.i2h.weight.grad.data.cpu().numpy()\n",
    "    o2o = rnn.o2o.weight.grad.data.cpu().numpy()\n",
    "    \n",
    "    norm_i2o = getNorm(i2o)\n",
    "    norm_i2h = getNorm(i2h)\n",
    "    norm_o2o = getNorm(o2o)\n",
    "    print(k, norm_i2o, norm_i2h, norm_o2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56467068,  0.34446806,  0.16331168, ..., -0.07057101,\n",
       "        -0.04895362,  0.55580968],\n",
       "       [ 0.01528262, -0.0856595 ,  0.11427888, ..., -0.07430661,\n",
       "        -0.0210433 ,  0.12422596],\n",
       "       [ 0.24313246,  0.07197672,  0.35094213, ..., -0.16292627,\n",
       "        -0.17816915,  0.45773843],\n",
       "       ..., \n",
       "       [-0.42307332,  0.29978159, -0.28576756, ...,  0.02942524,\n",
       "         0.03117448,  0.02862721],\n",
       "       [ 0.26053941, -0.13403273,  0.25640178, ...,  0.03677401,\n",
       "        -0.00440274,  0.41172504],\n",
       "       [-0.4059085 ,  0.0619502 , -0.37544531, ..., -0.10164777,\n",
       "        -0.07685494, -0.02930087]], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "i2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.699448"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(i2o, ord='fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
