{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, word2vec\n",
    "import pickle, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/lemmas.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences=data, size=100, negative=10, iter=10, seed=83, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros(model.syn0.shape)\n",
    "vocab = {k:i for i,k in enumerate(model.vocab.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in vocab.items():\n",
    "    embeddings[v] = model[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9479087 ,  0.45197308,  0.35786259, ...,  0.5015524 ,\n",
       "         0.13591142,  0.18483162],\n",
       "       [ 0.10213193, -0.51806766,  0.66322041, ...,  0.00413782,\n",
       "         0.37807727, -0.19085115],\n",
       "       [-0.25388241,  0.14046587,  0.89387089, ...,  0.43040872,\n",
       "         0.09118304,  0.14352459],\n",
       "       ..., \n",
       "       [-0.51958907,  0.09266288,  0.43625867, ...,  0.03089144,\n",
       "        -0.19175805,  0.16432409],\n",
       "       [-0.06909011,  0.24560058,  0.45053193, ..., -0.01179287,\n",
       "        -0.12295109,  0.15868132],\n",
       "       [-0.73705971,  0.11882165,  0.62680107, ...,  0.13950059,\n",
       "        -0.11896393,  0.19402087]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = {'vocab': vocab,\n",
    "         'embeddings': embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/lemmas_embeddings.pickle', 'wb') as g:\n",
    "    pickle.dump(total, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
